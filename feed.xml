<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://aixiuxiuxiu.github.io/blog/feed.xml" rel="self" type="application/atom+xml"/><link href="https://aixiuxiuxiu.github.io/blog/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-10T12:14:31+00:00</updated><id>https://aixiuxiuxiu.github.io/blog/feed.xml</id><title type="html">blank</title><subtitle>My name is Aixiu. I write here my learning notes for NLP and machine learning. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Find the Right and FREE PDF Extractor for Building RAG</title><link href="https://aixiuxiuxiu.github.io/blog/2024/pdfextractor/" rel="alternate" type="text/html" title="Find the Right and FREE PDF Extractor for Building RAG"/><published>2024-08-27T00:32:13+00:00</published><updated>2024-08-27T00:32:13+00:00</updated><id>https://aixiuxiuxiu.github.io/blog/2024/pdfextractor</id><content type="html" xml:base="https://aixiuxiuxiu.github.io/blog/2024/pdfextractor/"><![CDATA[<p>Recently, Retrieval-Augmented Generation (RAG) has emerged as a prominent approach that leverages large language models for building applications. However, in practical industrial settings, the primary bottleneck for the performance of RAG, particularly in terms of document retrieval, often lies not in the embedding model’s capabilities, but in the prior data ingestion pipeline. Building a RAG system begins with indexing documents, which are often in PDF format. This process typically starts with the use of PDF parsers or Optical Character Recognition (OCR) systems to extract text from the document’s pages.</p> <p>When a (machine-generated) PDF contains mostly text, there are various PDF extraction tools available on the market. Some companies offer paid solutions with advanced capabilities, while several open-source Python packages, such as <code class="language-plaintext highlighter-rouge">PDFPlumber</code> and <code class="language-plaintext highlighter-rouge">PyPDF</code>, are also very useful. In this discussion, I will compare two different free PDF extraction Python packages, highlighting their advantages and disadvantages.</p> <h2 id="pdfplumber-vs-pypdf">pdfplumber vs pypdf</h2> <p><a href="https://github.com/jsvine/pdfplumber"><code class="language-plaintext highlighter-rouge">pdfplumber</code></a> is built on <a href="https://github.com/goulu/pdfminer"><code class="language-plaintext highlighter-rouge">pdfminer.six</code></a>, enabling many customizable functions. This package can extract pages and text while preserving the layout. Additionally, it can identify the coordinates of words, allowing for the extraction of text within specific areas.</p> <p>On the other hand, <a href="https://pypi.org/project/pypdf/"><code class="language-plaintext highlighter-rouge">pypdf</code></a> also allows for text extraction while maintaining the layout. You can use <code class="language-plaintext highlighter-rouge">visitor</code> functions to control which parts of a page you want to process and extract. However, it does not support extracting the coordinates of words.</p> <p>The following example compares the extraction results of pdfplumber and pypdf using a PDF excerpt from the <a href="https://www.fedlex.admin.ch/eli/cc/24/233_245_233/en">Swiss Civil Code</a>. The PDF page presents a high level of complexity, with text that is discontinuously arranged and interspersed with numerous footnotes.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/blog/assets/img/pdf_example-480.webp 480w,/blog/assets/img/pdf_example-800.webp 800w,/blog/assets/img/pdf_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/blog/assets/img/pdf_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><code class="language-plaintext highlighter-rouge">pdfplumber</code> can parse various properties of characters, such as page number, text, coordinates, etc. You can use the <code class="language-plaintext highlighter-rouge">.crop()</code> method to crop a page into a bounding box, <code class="language-plaintext highlighter-rouge">.crop((x0, top, x1, bottom), relative=False, strict=True)</code>. Here is how I extract text from two boxes: one for the left side and the other for the right side. The x and y coordinate values can be determined using the x0, y0, x1, and y1 values of certain characters. For example, I use the x0 of the word ‘Art’ as the x0 for the right box (and x1 for the left box).</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/blog/assets/jupyter/pdfplumber.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <h2 id="evaluation">Evaluation</h2> <p>In the realm of building RAG frameworks, <code class="language-plaintext highlighter-rouge">LLAMAIndex</code> provides a <code class="language-plaintext highlighter-rouge">llama_parse</code> API. This API allows <code class="language-plaintext highlighter-rouge">LLAMAIndex</code> to efficiently parse and represent files for retrieval. However, it does not allow integration with the open-source PDF parser packages mentioned above.</p> <p><code class="language-plaintext highlighter-rouge">LangChain</code> integrates with various PDF parsers, such as PyPDF and PDFPlumber. In this section, I will compare the retrieval results using different PDF extraction methods within the LangChain framework.</p> <ul id="something-else" class="tab" data-tab="44cb9cca-159c-4ea7-b698-60a3ffc5b45d" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="44cb9cca-159c-4ea7-b698-60a3ffc5b45d" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="RAG"/><category term="data"/><summary type="html"><![CDATA[Recently, Retrieval-Augmented Generation (RAG) has emerged as a prominent approach that leverages large language models for building applications. However, in practical industrial settings, the primary bottleneck for the performance of RAG, particularly in terms of document retrieval, often lies not in the embedding model’s capabilities, but in the prior data ingestion pipeline. Building a RAG system begins with indexing documents, which are often in PDF format. This process typically starts with the use of PDF parsers or Optical Character Recognition (OCR) systems to extract text from the document’s pages.]]></summary></entry></feed>